{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Model Syntax\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RevBayes uses directed, acyclic graphs (DAGs) to depict model structure. In DAGs, the dependencies among variables flow in one direction only.\n",
    "\n",
    "The first, and simplest, type of node in a graphical model is a constant node. These behave essentially just like standard variables in any programming language, and take fixed values. This is also the only type of node that does not depend on the value of any other node in the graph (it is independent of all other nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x is a constant node with a fixed value\n",
    "x <- 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next type of node is a deterministic node. The values of deterministic nodes _do_ depend on the values of other nodes, but in a completely deterministic fashion. For instance, a simple deterministic node, `y`, could always have a value that is twice that of `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the starting value of x\n",
    "print(\"x = \" + x)\n",
    "\n",
    "# Defining y using the syntax for a deterministic node\n",
    "y := 2 * x\n",
    "print(\"y = \" + y)\n",
    "\n",
    "# Updating the value of x, but printing the new value of y\n",
    "# Notice that y itself was never directly changed!\n",
    "x <- 4.7\n",
    "print(\"y = \" + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the value of `y` changes as `x` changes, without having to make a new assignment to `y`.\n",
    "\n",
    "More complicated deterministic relationships could depend on the values of two or more other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more complicated deterministic relationship\n",
    "k <- 3\n",
    "m <- 2\n",
    "n := k^m\n",
    "print(\"n = \" + n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third, and final, type of node in a graphical model is a stochastic node. These nodes represent random variables, whose distribution must be specified when the node is created. The parameters of the stochastic node's distribution can either be fixed or can be determined by other variables (nodes) in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the probability of success for a Bernoulli with a constant node\n",
    "p <- 0.5\n",
    "\n",
    "# Creating a new stochastic node to represent the outcome of a Bernoulli trial\n",
    "z ~ dnBernoulli(p)\n",
    "print(\"z = \" + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each time you assign a distribution to a stochastic node, it draws a new value of the random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:10){\n",
    "    z ~ dnBernoulli(p)\n",
    "    print(\"z = \" + z)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### PRACTICE 1\n",
    "\n",
    "In the code block below, repeat what we did above for the Bernoulli distribution, but this time construct a stochastic node whose values are binomially distributed. Remember that the binomial distribution requires __two__ parameters. If you need some help, you can consult the list of RevBayes commands and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write Rev code to define a binomial distribution and draw 10 values from it.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to learn about the unknown values of parameters in our models, we must have a way to include observed data. In the context of graphical models, this is known as clamping. More specifically, we can clamp observations to stochastic nodes (think of the data as the observed values of a set of random variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a simple example of clamping an observation (success) to a Bernoulli r.v.\n",
    "z.clamp(1)\n",
    "print(\"Clamped value of z is \" + z + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our four basic building blocks in place (constant, deterministic, stochastic, and clamped stochastic nodes), we can begin building more interesting models.\n",
    "\n",
    "If we want to actually learn something about the probability of success, we need to record more than one observation. But since an individual Bernoulli r.v. has only a single outcome, we need to think about recording the outcomes of a series of Bernoulli r.v.s with a shared `p`. We also can't specify the exact value of `p` - otherwise there would be nothing to learn, because we would already know the value with certainty! Instead, we'll assign a prior probability distribution to `p`, which in this case will be a $Beta(1,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha <- 1\n",
    "beta <- 1\n",
    "p ~ dnBeta(alpha,beta)\n",
    "obs <- [1,0,0,1,0,1]\n",
    "for (i in 1:6){\n",
    "    obsNodes[i] ~ dnBernoulli(p)\n",
    "    obsNodes[i].clamp(obs[i])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### PRACTICE 2\n",
    "\n",
    "Try drawing out the full graphical model that we've just specified. Then compare to Figure 2 of HÃ¶hna et al (2014).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### PRACTICE 3\n",
    "\n",
    "How could we, more simply, specify the same model using a single binomial r.v.? Give it a try.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that you can print out the likelihood (i.e., the probability density of the current parameter value) for a given value of a model parameter, conditioned on the current states of other model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.probability()\n",
    "p.lnProbability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now back to the slides!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've specified our model and the dependencies among all its parameters, we need to set up the machinery to perform Markov chain Monte Carlo (MCMC) sampling from the posterior distribution. The first thing we do is to create a single model object that contains our entire graphical model. The one argument we pass to the model constructor can be any of the variables we've included in our model. Notice that we use the `=` assignment operator for the model, because it is a _workspace variable_ and not a part of the graphical model itself (i.e., it is not any of the four types of nodes we discussed previously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we'll use the set of Bernoullis with a shared p\n",
    "# Since alpha is one node in our graph, we can pass it as an argument to the model constructor\n",
    "myModel = model(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up our model, we need to assign Metropolis-Hastings moves (i.e., proposal distributions) to some of the variables so that we can sample from the posterior distribution. For the sake of convenience, we often create a vector called `moves` to store a list of all the moves applied to various parameters of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moves[1] = mvSlide(p,delta=0.1,weight=1)\n",
    "\n",
    "# If there were other parameters to infer, we could add additional moves here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also set up _monitors_ to allow us to keep track of the progress of the MCMC. We can print out our progress to the screen at an interval of our choosing using `printgen`, and we can also have parameter values, posteriors, likelihoods, and priors written to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors[1] = mnScreen(printgen=100,p)\n",
    "\n",
    "# If we were running this analysis from the command line, we could also add a monitor that prints to file\n",
    "# However, this doesn't seem to work from inside a Jupyter notebook\n",
    "# monitors[2] = mnModel(filename=\"binomialMCMC.log\",printgen=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take our model object, our moves, and our monitors and combine them into an MCMC object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myMCMC = mcmc(myModel, moves, monitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've put all these pieces together, we can simply tell RevBayes to run our MCMC analysis and for how long! It takes care of all the propose/accept/reject cycles for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMCMC.run(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "PRACTICE\n",
    "\n",
    "Now set up an MCMC analysis for the Normal model outlined in the slides.\n",
    "\n",
    "Put your Rev commands in a text file that can be run from the command line.\n",
    "\n",
    "Run your MCMC.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RevBayes",
   "language": "bash",
   "name": "revbayes_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "r"
   },
   "file_extension": ".Rev",
   "help_links": [
    {
     "text": "RevBayes",
     "url": "https://revbayes.org"
    },
    {
     "text": "RevBayes Kernel",
     "url": "https://github.com/sdwfrost/revbayes_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-rsrc",
   "name": "RevBayes",
   "pygments_lexer": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
